{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColNames:\n",
    "    time_ms = 'time[min]'\n",
    "    rri_ms = 'rri[ms]'\n",
    "    rr_systolic_mmHg = 'rr-systolic[mmHg]'\n",
    "    rr_diastolic_mmHg = 'rr-diastolic[mmHg]'\n",
    "    rr_mean_mmHg = 'rr-mean[mmHg]'\n",
    "    rr_flags = 'rr-flags[]'\n",
    "    ibi_ms = 'ibi[ms]'\n",
    "    file_name = 'file name'\n",
    "    sex = 'SEX [nominal codes: \"1\" woman; \"2\" man]'\n",
    "\n",
    "folder_path = 'HYPOL RECORDINGS/'\n",
    "\n",
    "class MyData:\n",
    "    def __init__(self, target, value):\n",
    "        self.target = target\n",
    "        self.value = value\n",
    "\n",
    "    def DFToVector(self):\n",
    "        if isinstance(self.value, pd.DataFrame):\n",
    "            return self.value.to_numpy().ravel()\n",
    "        \n",
    "    def DFToMatrix(self):\n",
    "        if isinstance(self.value, pd.DataFrame):\n",
    "            matrix = self.value.to_numpy(dtype=np.float32)\n",
    "            return matrix\n",
    "\n",
    "    def DFModify(self):\n",
    "        if isinstance(self.value, pd.DataFrame):\n",
    "            columns_to_remove = [ColNames.time_ms, ColNames.rr_flags]\n",
    "            self.value = self.value.drop(columns=columns_to_remove)\n",
    "            self.target -= 1\n",
    "\n",
    "\n",
    "class EKGDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample, label = self.data[idx], self.targets[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, label\n",
    "    \n",
    "def limit_row(df_dict, limit):\n",
    "    df_dict_res = {}\n",
    "    for key in df_dict:\n",
    "        df_temp = df_dict[key]\n",
    "        df_dict_res[key] = df_temp.head(limit)\n",
    "\n",
    "    return df_dict_res\n",
    "\n",
    "def merge_v1(df_dict, df_labels, target) -> dict[str,MyData]:\n",
    "    dic_res = {}\n",
    "    for key in df_dict:\n",
    "        dic_res[key] = MyData(df_labels.loc[df_labels[ColNames.file_name] == key].iloc[0][target], df_dict[key])\n",
    "    return dic_res\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cezary\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Cezary\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "torch.save(resnet.state_dict(), 'resnet18.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet18()\n",
    "resnet.load_state_dict(torch.load('resnet18.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Inicjalizacja pustego słownika\n",
    "ekg_dict = {}\n",
    "\n",
    "# Iteracja przez pliki w folderze\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Sprawdzenie, czy plik ma rozszerzenie .rea (załóżmy, że wszystkie pliki EKG mają to rozszerzenie)\n",
    "    if filename.endswith('.rea'):\n",
    "        # Pełna ścieżka do pliku\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Wczytanie pliku do DataFrame\n",
    "        df_temp = pd.read_csv(file_path, delimiter='\\t', header=0)\n",
    "        \n",
    "        # Dodanie do słownika, gdzie kluczem jest nazwa pliku, a wartością DataFrame\n",
    "        ekg_dict[filename] = df_temp\n",
    "\n",
    "df_main = pd.read_excel('HYPOL clinical characteristics.xls')\n",
    "ekg_dict_1000 = limit_row(ekg_dict, 700)\n",
    "merged_dict = merge_v1(ekg_dict_1000, df_main, ColNames.sex)\n",
    "for val in merged_dict.values():\n",
    "    val.DFModify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas: List[MyData] = list(merged_dict.values())\n",
    "targets = np.array([data.target for data in datas])\n",
    "values = np.array([data.DFToMatrix() for data in datas])\n",
    "X_train, X_test, y_train, y_test = train_test_split(values, targets, test_size=0.2, random_state=42, stratify=targets)\n",
    "\n",
    "# unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "# # Zastosowanie ADASYN do zwiększenia liczby danych 10-krotnie\n",
    "\n",
    "# target_ratio = {cls: count * 20 for cls, count in zip(unique_classes, class_counts)}\n",
    "\n",
    "# adasyn = ADASYN(sampling_strategy=target_ratio, random_state=42)\n",
    "# X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "# train_values_tensor = torch.tensor(train_values).double()  # Przekształć do tensora i typu float\n",
    "# test_values_tensor = torch.tensor(test_values).double()\n",
    "# train_targets_tensor = torch.tensor(train_targets)\n",
    "# test_targets_tensor = torch.tensor(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.5564269168036324\n",
      "Epoch 10, Loss: 0.36637295143944876\n",
      "Epoch 15, Loss: 0.3099286939416613\n",
      "Epoch 20, Loss: 0.1121119452374322\n",
      "Accuracy on test set: 57.14285714285714%\n",
      "Epoch 5, Loss: 0.5555388331413269\n",
      "Epoch 10, Loss: 0.2873157869492258\n",
      "Epoch 15, Loss: 0.2004724240728787\n",
      "Epoch 20, Loss: 0.2568089264844145\n",
      "Accuracy on test set: 45.45454545454545%\n",
      "Epoch 5, Loss: 0.5952494059290204\n",
      "Epoch 10, Loss: 0.38512344871248516\n",
      "Epoch 15, Loss: 0.32345695580754963\n",
      "Epoch 20, Loss: 0.19048451073467731\n",
      "Accuracy on test set: 65.45454545454545%\n",
      "Epoch 5, Loss: 0.6729573948042733\n",
      "Epoch 10, Loss: 0.6269346305302211\n",
      "Epoch 15, Loss: 0.5050546612058368\n",
      "Epoch 20, Loss: 0.28520082788808004\n",
      "Accuracy on test set: 54.54545454545454%\n",
      "Epoch 5, Loss: 0.6202406925814492\n",
      "Epoch 10, Loss: 0.48150877015931265\n",
      "Epoch 15, Loss: 0.27897091635635923\n",
      "Epoch 20, Loss: 0.36400813715798513\n",
      "Accuracy on test set: 63.63636363636363%\n",
      "Średnia dokładność modelu SVM na danych treningowych: nan%\n",
      "Średnia dokładność modelu SVM na danych testowych: 57.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cezary\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Cezary\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Zamień dane na tensor\n",
    "    \n",
    "    # Możesz dodać więcej transformacji, np. Normalizacja\n",
    "])\n",
    "# targets_tensor = torch.tensor(targets, dtype=torch.long).to(device)\n",
    "# values_tensor = torch.tensor(values, dtype=torch.float64).to(device)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "for train_index, test_index in skf.split(values, targets):\n",
    "    # Podział danych na zbiory treningowy i testowy\n",
    "    X_train, X_test = values[train_index], values[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "\n",
    "    # unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
    "    # target_ratio = {cls: count * 10 for cls, count in zip(unique_classes, class_counts)}\n",
    "    # adasyn = ADASYN(sampling_strategy=target_ratio, random_state=42)\n",
    "    # X_train, y_train = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Załaduj dane\n",
    "    train_dataset = EKGDataset(X_train, y_train, transform=transform)\n",
    "    test_dataset = EKGDataset(X_test, y_test, transform=transform)\n",
    "\n",
    "    # Załaduj dane za pomocą DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, pin_memory=True)\n",
    "\n",
    "    # Załaduj wstępnie wytrenowany model ResNet18\n",
    "    # resnet = models.resnet18(pretrained=True)\n",
    "    resnet = models.resnet18()\n",
    "    resnet.load_state_dict(torch.load('resnet18.pth'))\n",
    "    resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    # Zamień ostatnią warstwę klasyfikacyjną na nową, dopasowaną do naszego zadania\n",
    "    num_ftrs = resnet.fc.in_features\n",
    "    resnet.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 256),  # Pierwsza warstwa gęsta\n",
    "    nn.ReLU(),  # Funkcja aktywacji\n",
    "    nn.Linear(256, 128),  # Druga warstwa gęsta\n",
    "    nn.ReLU(),  # Funkcja aktywacji\n",
    "    nn.Linear(128, 2)  # Warstwa wyjściowa\n",
    ") # num_classes - liczba klas w naszym zbiorze danych\n",
    "\n",
    "    # Definicja funkcji kosztu i optymalizatora\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(resnet.parameters(), lr=0.001)\n",
    "    resnet.to(device)\n",
    "    # Trenowanie modelu\n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        resnet.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device, dtype=torch.float32)\n",
    "            outputs = resnet(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        if epoch % 5 == 4: \n",
    "            print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "\n",
    "    # Testowanie modelu na zbiorze testowym\n",
    "    resnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = resnet(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy on test set: {(correct/total)*100}%\")\n",
    "    test_accuracies.append((correct/total)*100)\n",
    "avg_train_accuracy = np.mean(train_accuracies)\n",
    "avg_test_accuracy = np.mean(test_accuracies)\n",
    "print(\"Średnia dokładność modelu SVM na danych treningowych: {:.2f}%\".format(avg_train_accuracy * 100))\n",
    "print(\"Średnia dokładność modelu SVM na danych testowych: {:.2f}%\".format(avg_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
